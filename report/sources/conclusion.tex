\chapter{Conclusion}

    We reached our base goal of generating visualizations that visibly correlate to the music when played alongside each other. We achieved our best results with the generator that was trained with the raw mel spectrogram as latent vectors. When applying our smoothing techniques during the video generation we have also achieved our secondary goal of having smooth transitions. Depending on the song those techniques do not necessarily have to be applied for a smooth result.

    There are many things we still want to try or investigate. We want to try different combinations of complexities regarding the generator and discriminator. Instead of randomly taking one sample from each song per epoch during training of the GANs, it should at least be modified to randomly select one sample from all songs in each step. Another option would be to construct a distribution of the samples from which we can then generate samples as needed.
    
    While the individual images of the combination of encoded features and InfoGAN look promising, the problem of images being very similar is still unsolved. Because the training takes multiple days before a judgement can be made it is very tedious and time-consuming. To prevent this issue in the future we would take a look at ProGANs where the output resolution is slowly increased during training. This significantly speeds up the training at the beginning and one is no longer required to decide on the final resolution from the start.

    Further, we would like to test around more with the features from the CRNN, as they seemed promising at first, already involving some smoothing of the features through the convolutions. A model with a much more consistent performance would be the first step to counter the varying results. Calculating a distribution from the different feature maps for training, to have a smooth feature space for the generators also sounds very promising. At last, there are still a variety of image datasets on which we want to train our generators, eventually producing more diverse visualizations.